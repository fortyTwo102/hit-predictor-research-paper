{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the necessary imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: \t XGBClassifier\n",
      "\n",
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'gamma': 'scale', 'kernel': 'rbf', 'random_state': 2}\n",
      "0.6709091727081085\n",
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf', 'random_state': 2}\n",
      "0.6185930495444659\n",
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'gamma': 'scale', 'kernel': 'rbf', 'random_state': 2}\n",
      "0.6546033584250146\n",
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   58.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'gamma': 'scale', 'kernel': 'rbf', 'random_state': 2}\n",
      "0.7121376811594203\n",
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 'scale', 'kernel': 'rbf', 'random_state': 2}\n",
      "0.6907356948228883\n",
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "print('MODEL: \\t XGBClassifier\\n' )\n",
    "for decade in ['60', '70', '80', '90', '00', '10']:\n",
    "    \n",
    "    ## pre-processing the dataset ----------------------------------------------------------\n",
    "    data = pd.read_csv('dataset//dataset-of-' + decade + 's.csv')\n",
    "    data = data.iloc[:, 3:] # removing track, artist name and uri\n",
    "    X, y = data.iloc[:, :-1], data.iloc[:, -1] \n",
    "\n",
    "    ## transforming the discrete features\n",
    "#     for column in ['mode', 'time_signature','key']:\n",
    "#         # X = X.drop(column, axis = 1)\n",
    "#         encoded_column = pd.get_dummies(X[column], prefix = column)\n",
    "#         X = X.join(encoded_column).drop(column, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "    \n",
    "#     # one-hot encoding the categorical values -----------------------------------------------\n",
    "#     enc = OneHotEncoder(handle_unknown = 'ignore') \n",
    "    \n",
    "#     enc_X_train = pd.DataFrame(enc.fit_transform(X_train[['key', 'time_signature', 'mode']]).toarray())\n",
    "#     X_train = X_train.join(enc_X_train).drop(['key', 'time_signature', 'mode'], axis = 1)\n",
    "#     X_train = pd.DataFrame(X_train).fillna(0)\n",
    "    \n",
    "#     enc_X_test = pd.DataFrame(enc.transform(X_test[['key', 'time_signature', 'mode']]).toarray())\n",
    "#     X_test = X_test.join(enc_X_test).drop(['key', 'time_signature', 'mode'], axis = 1)\n",
    "#     X_test = pd.DataFrame(X_test).fillna(0)\n",
    "    \n",
    "# #     for column in X_train.columns[15:]:\n",
    "# #         print (decade, column)\n",
    "# #         cnt = Counter(list(X_train[column]))  \n",
    "# #         pprint (cnt)\n",
    "    \n",
    "#     # Scaling the data -----------------------------------------------------------------------\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     X_train = scaler.fit_transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "\n",
    "#     for grid_search ---------------------------------------------------------------------------\n",
    "\n",
    "    enc_X = pd.DataFrame(enc.fit_transform(X[['key', 'time_signature', 'mode']]).toarray())\n",
    "    X = X.join(enc_X).drop(['key', 'time_signature', 'mode'], axis = 1)\n",
    "    X = pd.DataFrame(X).fillna(0)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "\n",
    "    ## Running the ML model ------------------------------------------------------------------\n",
    "    # model = XGBClassifier() # MLPClassifier(max_iter = 2000)\n",
    "    \n",
    "#     param_grid = {\n",
    "        \n",
    "#         'max_depth': [40, 100, 500],\n",
    "#         'n_estimators': [1000, 2000]\n",
    "        \n",
    "#     }\n",
    "\n",
    "    param_grid = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 'scale', 'auto'], 'kernel': ['rbf'], 'random_state' : [2]}  \n",
    "    \n",
    "#     model = RandomForestClassifier(n_estimators = 2000, random_state = 1) # SVC() # MLPClassifier(max_iter = 2000)\n",
    "    grid_search = GridSearchCV(estimator = SVC(), param_grid = param_grid, cv = 4, n_jobs = -1, verbose = 2, scoring = 'accuracy')\n",
    "\n",
    "    \n",
    "    pickle.dump(grid_search, open(decade + '-RF-GridSearchCV.p', 'wb'))\n",
    "    grid_search.fit(X, y)\n",
    "    print(grid_search.best_params_)\n",
    "    params = grid_search.best_params_\n",
    "    print(grid_search.best_score_)\n",
    "    \n",
    "#     model = SVC('C' = params['C'], 'gamma' = params['gamma'], 'random_state' = params['random_state'], kernel = params['kernel'])\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "# #     model = XGBClassifier()\n",
    "# #     model.fit(X_train, y_train)\n",
    "# #     y_pred = model.predict(X_test)\n",
    "    \n",
    "#     accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "#     print (decade + 's -', round(accuracy*100, 2), '')\n",
    "    \n",
    "    # try:\n",
    "    \n",
    "#     feature_importances = pd.DataFrame(model.feature_importances_, \\\n",
    "#                                        index = X_train.columns, \\\n",
    "#                                        columns=['importance']).sort_values('importance',\\\n",
    "#                                                                            ascending=False)\n",
    "    # print (feature_importances)    \n",
    "#     f_imp = model.feature_importances_\n",
    "#     f_imp = [round(x, 4) for x in f_imp]\n",
    "#     feature = X.columns\n",
    "    \n",
    "#     for x, y in sorted(zip(f_imp, feature), key=lambda x: x[0], reverse = True):\n",
    "#         print (x, y)\n",
    "\n",
    "    # except:\n",
    "    #    pass\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## RESULTS ##########\n",
    "\n",
    "# MODEL: \t SVC + OHE (mode, signature)\n",
    "\n",
    "# 60s - 75.63 \n",
    "# 70s - 77.68 \n",
    "# 80s - 79.06 \n",
    "# 90s - 83.39 \n",
    "# 00s - 83.94 \n",
    "# 10s - 81.72 \n",
    "\n",
    "# MODEL: \t SVC\n",
    "\n",
    "# 60s - 75.9 \n",
    "# 70s - 78.63 \n",
    "# 80s - 79.31 \n",
    "# 90s - 84.06 \n",
    "# 00s - 84.22 \n",
    "# 10s - 82.34 \n",
    "\n",
    "# MODEL: \t XGBClassifier\n",
    "\n",
    "# 60s - 76.09 \n",
    "# 70s - 78.2 \n",
    "# 80s - 79.93 \n",
    "# 90s - 83.88 \n",
    "# 00s - 85.64 \n",
    "# 10s - 84.58 \n",
    "\n",
    "# MODEL: \t RandomForestClassifier\n",
    "\n",
    "# 60s - 77.05 \n",
    "# 70s - 78.84 \n",
    "# 80s - 80.03 \n",
    "# 90s - 83.76 \n",
    "# 00s - 86.21 \n",
    "# 10s - 84.79 \n",
    "\n",
    "# MODEL: \t MLPClassifier\n",
    "\n",
    "# 60s - 74.55 \n",
    "# 70s - 76.09 \n",
    "# 80s - 76.51 \n",
    "# 90s - 81.94 \n",
    "# 00s - 83.31 \n",
    "# 10s - 82.4 \n",
    "\n",
    "# MODEL: \t RandomForestClassifier + get_dummies (key, mode, time_signature) + n_estimators = 2000\n",
    "\n",
    "# 60s - 76.98 \n",
    "# 70s - 79.14 \n",
    "# 80s - 80.13 \n",
    "# 90s - 84.6 \n",
    "# 00s - 86.72 \n",
    "# 10s - 85.16 \n",
    "\n",
    "# MODEL: \t RandomForestClassifier + OHE (key, mode, time_signature) + n_estimators = 2000\n",
    "\n",
    "# 60s - 77.09 \n",
    "# 70s - 79.06 \n",
    "# 80s - 80.32 \n",
    "# 90s - 84.78 \n",
    "# 00s - 86.44 \n",
    "# 10s - 85.0 \n",
    "\n",
    "\n",
    "\n",
    "# MODEL: \t RandomForestClassifier(n_estimators = 2000, random_state = 1) + + OHE (key, mode, time_signature)\n",
    "\n",
    "# 60s - 76.05 \n",
    "# 70s - 78.54 \n",
    "# 80s - 79.79 \n",
    "# 90s - 84.72 \n",
    "# 00s - 86.04 \n",
    "# 10s - 84.48 \n",
    "\n",
    "# MODEL: \t ExtraTreesClassifier\n",
    "\n",
    "# 60s - 74.55 \n",
    "# 70s - 77.42 \n",
    "# 80s - 78.0 \n",
    "# 90s - 84.0 \n",
    "# 00s - 85.47 \n",
    "# 10s - 83.96 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
